======================================================================
WEIGHT DIFF SAFETY ANALYSIS REPORT
======================================================================

Date: 2026-01-31 22:41:08 UTC
Base model:      google/gemma-2-2b-it
Finetuned model: Ananya8154/Gemma-2-2B-Indian-Law
Architecture:    gemma2
Fine-tuning:     Full
Layers:          26
Weight keys:     288

----------------------------------------------------------------------
CLASSIFICATION RESULT
----------------------------------------------------------------------
Label:      UNCERTAIN
Confidence: 42.6%
Phase:      1 (threshold_heuristics)

Explanation:
Threshold analysis (score=0.738, mode=full fine-tuning):
  - high_magnitude: 1.633 (TRIGGERED)
  - cosine_divergence: 1.033 (TRIGGERED)
  - deep_layer_concentration: 0.913 (below threshold)
  - low_rank_delta: 0.594 (below threshold)
  - layer_l2_gini: 0.356 (below threshold)
  - attention_heavy_modification: 0.333 (below threshold)
  - heavy_tailed_deltas: 0.104 (below threshold)
  - stealth_kurtosis_magnitude: 0.004 (below threshold)

----------------------------------------------------------------------
RISK SIGNALS
----------------------------------------------------------------------
  high_magnitude                             1.6325 |################################ << TRIGGERED
  cosine_divergence                          1.0325 |#################### << TRIGGERED
  deep_layer_concentration                   0.9132 |##################
  low_rank_delta                             0.5935 |###########
  layer_l2_gini                              0.3557 |#######
  attention_heavy_modification               0.3326 |######
  heavy_tailed_deltas                        0.1039 |##
  stealth_kurtosis_magnitude                 0.0042 |

----------------------------------------------------------------------
KEY FEATURES
----------------------------------------------------------------------
  Deep/Shallow L2 Ratio                    1.095881
  Attention/MLP L2 Ratio                   0.498871
  Global Mean Cosine Similarity            0.996289
  Global Mean Frobenius Ratio              0.081626
  Total L2 Norm                            681.226835
  Mean SV Concentration                    0.207737
  Mean Effective Rank                      9.126165
  Attention Mean Kurtosis                  1.574274
  Layer L2 Gini Coefficient                0.021341

----------------------------------------------------------------------
PER-COMPONENT SUMMARY
----------------------------------------------------------------------
  ATTENTION     L2=2.469529  Cosine=0.993239  Frob=0.116332
  MLP           L2=4.950238  Cosine=0.992176  Frob=0.140820
  NORM          L2=0.102851  Cosine=0.999991  Frob=0.003731

======================================================================